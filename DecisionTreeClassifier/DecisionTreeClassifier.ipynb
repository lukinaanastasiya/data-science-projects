{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.datasets import make_classification, make_regression, load_digits, load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropy $F(X) = -\\sum_{i = 1}^K p_i \\log_2(p_i)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "    y = y.tolist()\n",
    "    unique_state = set(y)\n",
    "    dict_val = {} # Dictionary for unique values and its number\n",
    "    for i in unique_state:\n",
    "        dict_val[i] = y.count(i)\n",
    "    total = len(y)\n",
    "    ent = 0\n",
    "    for i in unique_state:\n",
    "        pi = dict_val[i]/total\n",
    "        ent += (pi * math.log2(pi))\n",
    "    return -ent "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gini impurity $F(X) = 1 -\\sum_{i = 1}^K p_i^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(y):\n",
    "    y = y.tolist()\n",
    "    unique_state = set(y)\n",
    "    dict_val = {} # Dictionary for unique values and its number\n",
    "    for i in unique_state:\n",
    "        dict_val[i] = y.count(i)\n",
    "    total = len(y)\n",
    "    gini = 0\n",
    "    for i in unique_state:\n",
    "        pi = dict_val[i]/total\n",
    "        gini += (pi*pi)\n",
    "    return 1 - gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Associate criterion with particular function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria_dict = {'entropy': entropy, 'gini': gini}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating a prediction in a leaf - the most popular class in leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_leaf(y):\n",
    "    return np.bincount(y).argmax() # bincount - count number of enterances of each int value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, feature_idx=0, threshold=0, labels=None, left=None, right=None):\n",
    "        self.feature_idx = feature_idx\n",
    "        self.threshold = threshold\n",
    "        self.labels = labels\n",
    "        self.left = left\n",
    "        self.right = right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier(BaseEstimator):\n",
    "    \n",
    "    # Initiate node and set parameters\n",
    "    def __init__(self, max_depth=np.inf, min_samples_split=2, criterion='gini', debug=False):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.criterion = criterion\n",
    "        self.debug = debug\n",
    "        self._leaf_value = classification_leaf\n",
    "        self._criterion_function = criteria_dict[self.criterion]\n",
    "    \n",
    "    # Split the data by two parts\n",
    "    def _functional(self, X, y, feature_idx, threshold):\n",
    "        mask = X[:, feature_idx] < threshold\n",
    "        n_obj = X.shape[0]\n",
    "        n_left = np.sum(mask)\n",
    "        n_right = n_obj - n_left    \n",
    "        if n_left > 0 and n_right > 0:\n",
    "            return self._criterion_function(y) - (n_left / n_obj) * \\\n",
    "                    self._criterion_function(y[mask]) - (n_right / n_obj) * \\\n",
    "                    self._criterion_function(y[~mask])\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def _build_tree(self, X, y, depth=1):\n",
    "        max_functional = 0\n",
    "        best_feature_idx = None\n",
    "        best_threshold = None\n",
    "        n_samples, n_features = X.shape     \n",
    "    \n",
    "        if len(np.unique(y)) == 1:\n",
    "            return Node(labels=y)\n",
    "\n",
    "        if depth < self.max_depth and n_samples >= self.min_samples_split:\n",
    "            for feature_idx in range(n_features):\n",
    "                threshold_values = np.unique(X[:, feature_idx])    \n",
    "                functional_values = [self._functional(X, y, feature_idx, threshold) for threshold in threshold_values]\n",
    "                \n",
    "                best_threshold_idx = np.nanargmax(functional_values)\n",
    "                    \n",
    "                if functional_values[best_threshold_idx] > max_functional:\n",
    "                    max_functional = functional_values[best_threshold_idx]\n",
    "                    best_threshold = threshold_values[best_threshold_idx]\n",
    "                    best_feature_idx = feature_idx\n",
    "                    best_mask = X[:, feature_idx] < best_threshold\n",
    "    \n",
    "        if best_feature_idx is not None:\n",
    "            return Node(feature_idx=best_feature_idx, threshold=best_threshold, \n",
    "                        left=self._build_tree(X[best_mask, :], y[best_mask], depth + 1),\n",
    "                        right=self._build_tree(X[~best_mask, :], y[~best_mask], depth + 1))\n",
    "        else:\n",
    "            return Node(labels=y)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self._n_classes = len(np.unique(y))\n",
    "        self.root = self._build_tree(X, y)\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        preds = []\n",
    "        for x in X:\n",
    "            node = self.root\n",
    "            while node.labels is None:\n",
    "                if x[node.feature_idx] < node.threshold:\n",
    "                    node = node.left\n",
    "                else:\n",
    "                    node = node.right\n",
    "            preds.append(self._leaf_value(node.labels))\n",
    "        return np.array(preds)\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        preds = []\n",
    "        for x in X:\n",
    "            node = self.root\n",
    "            while node.labels is None:\n",
    "                if x[node.feature_idx] < node.threshold:\n",
    "                    node = node.left\n",
    "                else:\n",
    "                    node = node.right\n",
    "            for i in range(self._n_classes):\n",
    "                # Calculate probabilities\n",
    "                preds.append([len(node.labels[node.labels == k])/len(node.labels) for k in range(self._n_classes)])\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the data with make_classification and split by train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_features=7, n_redundant=0, n_samples=400, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate accuracy for our written tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for our tree: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "clf = MyDecisionTreeClassifier(max_depth=4, criterion='gini')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "prob_pred = clf.predict_proba(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy for our tree:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate accuracy for tree from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for sklearn tree: 0.825\n"
     ]
    }
   ],
   "source": [
    "clf_2 = DecisionTreeClassifier(max_depth=4, criterion='gini')\n",
    "clf_2.fit(X_train, y_train)\n",
    "y_pred = clf_2.predict(X_test)\n",
    "prob_pred = clf_2.predict_proba(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy for sklearn tree:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking on another dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../credit_scoring_sample.csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_columns_names = data.columns.values\n",
    "independent_columns_names = [x for x in data if x != 'SeriousDlqin2yrs']\n",
    "independent_columns_names\n",
    "for col in data.columns:\n",
    "        data[col]= data[col].fillna(data[col].median())\n",
    "X = data[independent_columns_names].values\n",
    "y = data['SeriousDlqin2yrs'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*It spends a lot of time but works*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for our tree: 0.8332716916931726\n"
     ]
    }
   ],
   "source": [
    "clf = MyDecisionTreeClassifier(max_depth=4, criterion='entropy')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "prob_pred = clf.predict_proba(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy for our tree:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for sklearn tree: 0.8332716916931726\n"
     ]
    }
   ],
   "source": [
    "clf_2 = DecisionTreeClassifier(max_depth=4, criterion='entropy')\n",
    "clf_2.fit(X_train, y_train)\n",
    "y_pred = clf_2.predict(X_test)\n",
    "prob_pred = clf_2.predict_proba(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy for sklearn tree:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*with entropy results are the same...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Notice that classifier works with numpy arrays. So you should make ndarray from pd Dataframe*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
